
########################
HIVE Query execution:
########################

SQL queries are submitted to Hive and they are executed as follows:

    -- Hive compiles the query.

    -- An execution engine, such as Tez or MapReduce, executes the compiled query.

    -- The resource manager, YARN, allocates resources for applications across the cluster.

    -- The data that the query acts upon resides in HDFS (Hadoop Distributed File System). Supported data formats are ORC, AVRO, Parquet, and text.

    -- Query results are then returned over a JDBC/ODBC connection.
    

####################
Hive Architecture
####################

- Hive Clients

- Hive services - Hiveserver2, beeline, Hive Driver(receives hql, creates session handles for the query and sends to compiler), Hive Compiler (comiles, typecheks, parses with metdata and generates execution plan called DAG where each stage is MRjob, HDFS ops, metastore ops), Optimizer, Execution Engine, Metastore (Metastore is a central repository that stores the metadata information about the structure of tables and partitions, including column and column type information.
  It also stores information of serializer and deserializer, required for the read/write operation, and HDFS files where data is stored. This metastore is generally a relational database.)

- Processing Framework and Resource Management (Hive internally uses a MapReduce framework as a defacto engine for executing the queries.)

- Distributed Storage (Hive is built on top of Hadoop, so it uses the underlying HDFS)


#################
Working of Hive:
#################	
	executeQuery
	getPlan (driver accepts the query, creates a session handle for the query, and passes the query to the compiler for generating the execution plan.)
	getMetaData (compiler sends metadeta request to metastore)
	sendMetaData (metastore sends the metadata to the compiler)
	sendPlan (compiler then sends the generated execution plan to the driver)
	executePlan (river sends the execution plan to the execution engine for executing the plan)
	submit job to MapReduce ()
  
  
 ##############################
 Advanced Interview Questions
 ##############################
 
 1) How to manage multiple hive batch jobs:
  
	Yarn queue mapping..
	Configure a queue for batch processing
	You can configure the capacity scheduler queues to scale a Hive batch job for your environment. YARN uses the queues to allocate Hadoop cluster resources among users and groups.

 2) What is managed table and external table in hive:
 
	Managed tables are Hive owned tables where the entire lifecycle of the tablesâ€™ data are managed and controlled by Hive. External tables are tables where Hive has loose coupling with the data.
	All the write operations to the Managed tables are performed using Hive SQL commands. If a Managed table or partition is dropped, the data and metadata associated with that table or partition are deleted. The transactional semantics (ACID) are also supported only on Managed tables.
	The writes on External tables can be performed using Hive SQL commands but data files can also be accessed and managed by processes outside of Hive. If an External table or partition is dropped, only the metadata associated with the table or partition is deleted but the underlying data files stay intact. A typical example for External table is to run analytical queries on HBase or Druid owned data via Hive, where data files are written by HBase or Druid and Hive reads them for analytics.
	Hive supports replication of External tables with data to target cluster and it retains all the properties of External tables.
	The data files permission and ownership are preserved so that the relevant external processes can continue to write in it even after failover. 

 
 3) What is partitionBy and ClusterBy in hive:
 
 4) How can you change the execution engine of hive:
 
 	By setting the property hive.execution.engine = 'Tez' during the local session or setting it up globally we can set our required execution engine.
 
 
 
 
